{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ljkrajewski/jupyter_notebooks/blob/main/flux/GUFlux.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grand Unified Flux\n",
        "With much love to @camenduru for the [flux_jupyter](https://github.com/camenduru/flux-jupyter) repository."
      ],
      "metadata": {
        "id": "Dm3lnv1tYjwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run this cell by itself first.\n",
        "!pip3 install -U xformers --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install -q torchsde einops diffusers accelerate gradio==3.50.2 python-multipart==0.0.12\n",
        "!apt -y install -qq aria2\n",
        "\n",
        "# Install torchvision with CUDA support\n",
        "#!pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip uninstall torch torchvision -y\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
      ],
      "metadata": {
        "cellView": "form",
        "id": "tdMZmIsyL31t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f48ce14a-d18b-4677-8f1d-41cfce893b4a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting xformers\n",
            "  Downloading https://download.pytorch.org/whl/cu124/xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xformers) (1.26.4)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from xformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->xformers)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->xformers)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->xformers)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->xformers)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->xformers)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->xformers)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->xformers)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->xformers)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->xformers)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->xformers)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->xformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->xformers) (3.0.2)\n",
            "Downloading https://download.pytorch.org/whl/cu124/xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl (43.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, xformers\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 xformers-0.0.29.post3\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.6/130.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-genai 1.4.0 requires websockets<15.0dev,>=13.0, but you have websockets 11.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mThe following additional packages will be installed:\n",
            "  libaria2-0 libc-ares2\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2\n",
            "0 upgraded, 3 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 1,513 kB of archives.\n",
            "After this operation, 5,441 kB of additional disk space will be used.\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 125044 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Found existing installation: torchvision 0.21.0+cu124\n",
            "Uninstalling torchvision-0.21.0+cu124:\n",
            "  Successfully uninstalled torchvision-0.21.0+cu124\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl (768.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m768.5/768.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch, torchvision\n",
            "Successfully installed torch-2.6.0+cu124 torchvision-0.21.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Restart the notebook now (if required)."
      ],
      "metadata": {
        "id": "s8nKx3vOMAf7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RI6jaqNcaIgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download code and models\n",
        "%cd /content\n",
        "!git clone -b totoro4 https://github.com/camenduru/ComfyUI /content/TotoroUI\n",
        "%cd /content/TotoroUI\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/flux1-dev-fp8-all-in-one.safetensors -d /content/TotoroUI/models/checkpoints -o flux1-dev-fp8-all-in-one.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/flux_realism_lora.safetensors -d /content/TotoroUI/models/loras -o flux_realism_lora.safetensors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "SCcSaVy9aS3u",
        "outputId": "f3d5c563-c536-4985-e827-f5bdc574fdf1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into '/content/TotoroUI'...\n",
            "remote: Enumerating objects: 14652, done.\u001b[K\n",
            "remote: Total 14652 (delta 0), reused 0 (delta 0), pack-reused 14652 (from 1)\u001b[K\n",
            "Receiving objects: 100% (14652/14652), 21.12 MiB | 14.37 MiB/s, done.\n",
            "Resolving deltas: 100% (9820/9820), done.\n",
            "/content/TotoroUI\n",
            " *** Download Progress Summary as of Mon Mar 17 15:45:33 2025 *** \n",
            "=\n",
            "[#4f89dc 8.4GiB/16GiB(52%) CN:16 DL:154MiB ETA:50s]\n",
            "FILE: /content/TotoroUI/models/checkpoints/flux1-dev-fp8-all-in-one.safetensors\n",
            "-\n",
            "\n",
            " *** Download Progress Summary as of Mon Mar 17 15:46:48 2025 *** \n",
            "=\n",
            "[#4f89dc 12GiB/16GiB(79%) CN:16 DL:0B]\n",
            "FILE: /content/TotoroUI/models/checkpoints/flux1-dev-fp8-all-in-one.safetensors\n",
            "-\n",
            "\n",
            " *** Download Progress Summary as of Mon Mar 17 15:47:49 2025 *** \n",
            "=\n",
            "[#4f89dc 16GiB/16GiB(99%) CN:16 DL:226MiB]\n",
            "FILE: /content/TotoroUI/models/checkpoints/flux1-dev-fp8-all-in-one.safetensors\n",
            "-\n",
            "\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "4f89dc|\u001b[1;32mOK\u001b[0m  |    83MiB/s|/content/TotoroUI/models/checkpoints/flux1-dev-fp8-all-in-one.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "ebdc72|\u001b[1;32mOK\u001b[0m  |   156MiB/s|/content/TotoroUI/models/loras/flux_realism_lora.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761,
          "referenced_widgets": [
            "e3c4e2f94be84b7ca95ff23542f9d4a7",
            "d2777637b901484ebcc7cd9cd69b9cf5",
            "f49e341e04db47ba93bac6b604f5fa8f",
            "4467568d74074ed6b622cd4fb30f8a0b",
            "b61d265d37164e0f9325422b9a2e700b",
            "095c0b732540439489d38419475a79e1",
            "6694fbff905d42a98197955fe066f061",
            "f26b14db42a24a619b6acd8651748a96",
            "8875cbd62d30494e82be1a42f65bf7a0",
            "5263daf6319344f18e2e5784d5007fff",
            "b13bc16817b34610808af5884fc1afb6"
          ]
        },
        "outputId": "2e0e4a05-9771-43c3-8dc5-2716e70bdc22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://efffe1e5feae1ded3e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "----\n",
            "Generating image 1/1, prompt 1/3...\n",
            "\n",
            "Seed:  188246890702172501\n",
            "Dimentions:  1024x1024 (portrait)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3c4e2f94be84b7ca95ff23542f9d4a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata added successfully to /content/flux.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 407, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1550, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1185, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 661, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-3-5f3b23b227b8>\", line 168, in generate_wrapper\n",
            "    update(value=new_image_name)\n",
            "    ^^^^^^\n",
            "NameError: name 'update' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://efffe1e5feae1ded3e.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#@title Define local routines and start gradio\n",
        "import math\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from PIL.PngImagePlugin import PngInfo\n",
        "import nodes\n",
        "from nodes import NODE_CLASS_MAPPINGS\n",
        "from totoro_extras import nodes_custom_sampler\n",
        "from totoro_extras import nodes_flux\n",
        "from totoro import model_management\n",
        "import gradio as gr\n",
        "import os\n",
        "import itertools\n",
        "import re\n",
        "\n",
        "def add_ai_metadata(image_path, prompt, seed, steps, guidance, sampler_name, scheduler, lora_strength_model, lora_strength_clip):\n",
        "    \"\"\"\n",
        "    Adds metadata related to a stable diffusion image generation to a PNG image file.\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to the PNG image file.\n",
        "        prompt: The text prompt used for image generation.\n",
        "        seed: The random seed used for image generation.\n",
        "        steps: The number of denoising steps.\n",
        "        guidance: The classifier-free guidance scale (cfg_scale).\n",
        "        sampler_name: The name of the sampler used.\n",
        "        scheduler: The scheduler used.\n",
        "        lora_strength_model: The strength of the LoRA model.\n",
        "        lora_strength_clip: The strength of the LoRA CLIP.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        img = Image.open(image_path)\n",
        "        png_info = PngInfo()\n",
        "\n",
        "        png_info.add_text(\"Prompt\", prompt)\n",
        "        png_info.add_text(\"Seed\", str(seed))\n",
        "        png_info.add_text(\"Steps\", str(steps))\n",
        "        png_info.add_text(\"Guidance\", str(guidance))\n",
        "        png_info.add_text(\"Sampler\", sampler_name)\n",
        "        png_info.add_text(\"Scheduler\", scheduler)\n",
        "        png_info.add_text(\"LoRA\", \"flux_realism_lora\")\n",
        "        png_info.add_text(\"LoRA Strength Model\", str(lora_strength_model))\n",
        "        png_info.add_text(\"LoRA Strength CLIP\", str(lora_strength_clip))\n",
        "        img.save(image_path, pnginfo=png_info)\n",
        "        print(f\"Metadata added successfully to {image_path}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at {image_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "def optimal_dimensions(wh_ratio):\n",
        "    \"\"\"\n",
        "    Calculates optimal dimensions for Stable Diffusion.\n",
        "\n",
        "    Args:\n",
        "      wh_ratio (str): Width-to-height ratio in the format \"width:height\".\n",
        "\n",
        "    Returns:\n",
        "      A tuple of (new_width, new_height) representing the optimal dimensions.\n",
        "    \"\"\"\n",
        "    sw, sh = wh_ratio.split(':')\n",
        "    w, h = int(sw), int(sh)\n",
        "    c = math.sqrt(1024**2 / (w * h))\n",
        "    new_width = int(((w * c) // 16) * 16)\n",
        "    new_height = int(((h * c) // 16) * 16)\n",
        "    #print(f\"Optimal dimensions: {new_width}x{new_height}\")\n",
        "    return new_width, new_height\n",
        "\n",
        "CheckpointLoaderSimple = NODE_CLASS_MAPPINGS[\"CheckpointLoaderSimple\"]()\n",
        "LoraLoader = NODE_CLASS_MAPPINGS[\"LoraLoader\"]()\n",
        "FluxGuidance = nodes_flux.NODE_CLASS_MAPPINGS[\"FluxGuidance\"]()\n",
        "RandomNoise = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"RandomNoise\"]()\n",
        "BasicGuider = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"BasicGuider\"]()\n",
        "KSamplerSelect = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"KSamplerSelect\"]()\n",
        "BasicScheduler = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"BasicScheduler\"]()\n",
        "SamplerCustomAdvanced = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"SamplerCustomAdvanced\"]()\n",
        "VAELoader = NODE_CLASS_MAPPINGS[\"VAELoader\"]()\n",
        "VAEDecode = NODE_CLASS_MAPPINGS[\"VAEDecode\"]()\n",
        "EmptyLatentImage = NODE_CLASS_MAPPINGS[\"EmptyLatentImage\"]()\n",
        "\n",
        "with torch.inference_mode():\n",
        "    unet, clip, vae = CheckpointLoaderSimple.load_checkpoint(\"flux1-dev-fp8-all-in-one.safetensors\")\n",
        "\n",
        "def closestNumber(n, m):\n",
        "    q = int(n / m)\n",
        "    n1 = m * q\n",
        "    if (n * m) > 0:\n",
        "        n2 = m * (q + 1)\n",
        "    else:\n",
        "        n2 = m * (q - 1)\n",
        "    if abs(n - n1) < abs(n - n2):\n",
        "        return n1\n",
        "    return n2\n",
        "\n",
        "@torch.inference_mode()\n",
        "#def generate(positive_prompt, width, height, seed, steps, sampler_name, scheduler, guidance, lora_strength_model, lora_strength_clip):\n",
        "def generate(positive_prompt, wh_ratio, orientation, seed, steps, sampler_name, scheduler, guidance, lora_strength_model, lora_strength_clip):\n",
        "    global unet, clip\n",
        "    if seed == 0:\n",
        "        seed = random.randint(0, 18446744073709551615)\n",
        "    print(f\"\\nSeed:  {seed}\")\n",
        "    #print(f\"Prompt:  {positive_prompt}\")\n",
        "    width, height = optimal_dimensions(wh_ratio)\n",
        "    if orientation == \"portrait\":\n",
        "        width, height = height, width\n",
        "    print(f\"Dimentions:  {width}x{height} ({orientation})\")\n",
        "    #print(f\"Width:  {width}\\tType:  {type(width)}\")\n",
        "    #print(f\"Height:  {height}\\tType:  {type(height)}\")\n",
        "    #print(f\"Steps:  {steps}\\tType:  {type(steps)}\n",
        "    unet_lora, clip_lora = LoraLoader.load_lora(unet, clip, \"flux_realism_lora.safetensors\", lora_strength_model, lora_strength_clip)\n",
        "    cond, pooled = clip_lora.encode_from_tokens(clip_lora.tokenize(positive_prompt), return_pooled=True)\n",
        "    cond = [[cond, {\"pooled_output\": pooled}]]\n",
        "    cond = FluxGuidance.append(cond, guidance)[0]\n",
        "    noise = RandomNoise.get_noise(seed)[0]\n",
        "    guider = BasicGuider.get_guider(unet_lora, cond)[0]\n",
        "    sampler = KSamplerSelect.get_sampler(sampler_name)[0]\n",
        "    sigmas = BasicScheduler.get_sigmas(unet_lora, scheduler, steps, 1.0)[0]\n",
        "    latent_image = EmptyLatentImage.generate(closestNumber(width, 16), closestNumber(height, 16))[0]\n",
        "    sample, sample_denoised = SamplerCustomAdvanced.sample(noise, guider, sampler, sigmas, latent_image)\n",
        "    decoded = VAEDecode.decode(vae, sample)[0].detach()\n",
        "    Image.fromarray(np.array(decoded*255, dtype=np.uint8)[0]).save(\"/content/flux.png\")\n",
        "    add_ai_metadata(\"/content/flux.png\", positive_prompt, seed, steps, guidance, sampler_name, scheduler, lora_strength_model, lora_strength_clip)\n",
        "    return \"/content/flux.png\"\n",
        "\n",
        "def round_robin_prompts(prompt):\n",
        "    \"\"\"\n",
        "    Generates all possible permutations of a prompt with round-robin sections.\n",
        "\n",
        "    Args:\n",
        "        prompt: A natural language prompt containing round-robin sections\n",
        "                enclosed in curly braces with items separated by '|'.\n",
        "                Example: \"a {red|blue} cup on a {table|chair}\"\n",
        "\n",
        "    Returns:\n",
        "        A list of strings, where each string is a possible permutation of the prompt.\n",
        "    \"\"\"\n",
        "\n",
        "    sections = []\n",
        "    split_prompt = re.split(r'({.*?})', prompt)\n",
        "\n",
        "    for part in split_prompt:\n",
        "        if part.startswith('{') and part.endswith('}'):\n",
        "            items = part[1:-1].split('|')\n",
        "            sections.append(items)\n",
        "        else:\n",
        "            sections.append([part])  # Non-round-robin parts are treated as single-item sections\n",
        "\n",
        "    combinations = list(itertools.product(*sections))\n",
        "    result = []\n",
        "    for combo in combinations:\n",
        "        result.append(\"\".join(combo))\n",
        "    return result\n",
        "\n",
        "def generate_wrapper(positive_prompt, quantity, wh_ratio, orientation, seed, steps, sampler_name, scheduler, guidance, lora_strength_model, lora_strength_clip):\n",
        "    prompts = round_robin_prompts(positive_prompt)\n",
        "    num_prompts = len(prompts)\n",
        "    for p_idx, prompt in enumerate(prompts):\n",
        "        #print(f\"Prompt:  {prompt}\")\n",
        "        for i in range(quantity):\n",
        "            print(f\"----\\nGenerating image {i+1}/{quantity}, prompt {p_idx+1}/{num_prompts}...\")\n",
        "            generate(prompt, wh_ratio, orientation, seed, steps, sampler_name, scheduler, guidance, lora_strength_model, lora_strength_clip)\n",
        "            new_image_name=f\"/content/flux{p_idx+1}-{i+1}.png\"\n",
        "            os.rename(\"/content/flux.png\", new_image_name)\n",
        "            output_image.value = new_image_name\n",
        "            output_image.update(value=new_image_name)\n",
        "    return new_image_name\n",
        "\n",
        "with gr.Blocks(analytics_enabled=False) as demo:\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            positive_prompt = gr.Textbox(lines=3, interactive=True, value=\"Anime drawing, full body portrait, attractive 19-year-old Caucasian woman, long straight blonde hair, red lipstick, white button-up blouse, black neck tie, black suspenders, tan suit jacket, tan shorts, tan pantyhose, tan flat shoes, smiling, sitting in a recliner, legs crossed\", label=\"Prompt\")\n",
        "            #width = gr.Slider(minimum=256, maximum=2048, value=1024, step=16, label=\"width\")\n",
        "            #height = gr.Slider(minimum=256, maximum=2048, value=1024, step=16, label=\"height\")\n",
        "            with gr.Row():\n",
        "                #wh_ratio = gr.Textbox(lines=1, interactive=True, value=\"4:7\", label=\"width:height ratio\")\n",
        "                wh_ratio = gr.Dropdown([\"1:1\",\"2:1\",\"3:2\",\"4:3\",\"5:3\",\"7:4\",\"9:7\",\"16:9\",\"21:11\",\"17:15\"], value=\"7:4\", label=\"width:height ratio\")\n",
        "                orientation = gr.Dropdown([\"portrait\", \"landscape\"], label=\"orientation\", value=\"portrait\")\n",
        "                quantity = gr.Slider(minimum=1, maximum=10, value=1, step=1, label=\"quantity per prompt\")\n",
        "                #width, height = optimal_dimensions(wh_ratio.value)\n",
        "            seed = gr.Slider(minimum=0, maximum=18446744073709551615, value=0, step=1, label=\"seed (0=random)\")\n",
        "            steps = gr.Slider(minimum=4, maximum=50, value=20, step=1, label=\"steps\")\n",
        "            guidance = gr.Slider(minimum=0, maximum=20, value=3.5, step=0.5, label=\"guidance\")\n",
        "            lora_strength_model = gr.Slider(minimum=0, maximum=1, value=1.0, step=0.1, label=\"lora_strength_model\")\n",
        "            lora_strength_clip = gr.Slider(minimum=0, maximum=1, value=1.0, step=0.1, label=\"lora_strength_clip\")\n",
        "            sampler_name = gr.Dropdown([\"euler\", \"heun\", \"heunpp2\", \"heunpp2\", \"dpm_2\", \"lms\", \"dpmpp_2m\", \"ipndm\", \"deis\", \"ddim\", \"uni_pc\", \"uni_pc_bh2\"], label=\"sampler_name\", value=\"euler\")\n",
        "            scheduler = gr.Dropdown([\"normal\", \"sgm_uniform\", \"simple\", \"ddim_uniform\"], label=\"scheduler\", value=\"simple\")\n",
        "            generate_button = gr.Button(\"Generate\")\n",
        "        with gr.Column():\n",
        "            output_image = gr.Image(label=\"Generated image\", interactive=False)\n",
        "\n",
        "    #generate_button.click(fn=generate, inputs=[positive_prompt, width, height, seed, steps, sampler_name, scheduler, guidance, lora_strength_model, lora_strength_clip], outputs=output_image)\n",
        "    generate_button.click(fn=generate_wrapper, inputs=[positive_prompt, quantity, wh_ratio, orientation, seed, steps, sampler_name, scheduler, guidance, lora_strength_model, lora_strength_clip], outputs=output_image)\n",
        "\n",
        "demo.queue().launch(inline=False, share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e3c4e2f94be84b7ca95ff23542f9d4a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2777637b901484ebcc7cd9cd69b9cf5",
              "IPY_MODEL_f49e341e04db47ba93bac6b604f5fa8f",
              "IPY_MODEL_4467568d74074ed6b622cd4fb30f8a0b"
            ],
            "layout": "IPY_MODEL_b61d265d37164e0f9325422b9a2e700b"
          }
        },
        "d2777637b901484ebcc7cd9cd69b9cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_095c0b732540439489d38419475a79e1",
            "placeholder": "​",
            "style": "IPY_MODEL_6694fbff905d42a98197955fe066f061",
            "value": "100%"
          }
        },
        "f49e341e04db47ba93bac6b604f5fa8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f26b14db42a24a619b6acd8651748a96",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8875cbd62d30494e82be1a42f65bf7a0",
            "value": 20
          }
        },
        "4467568d74074ed6b622cd4fb30f8a0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5263daf6319344f18e2e5784d5007fff",
            "placeholder": "​",
            "style": "IPY_MODEL_b13bc16817b34610808af5884fc1afb6",
            "value": " 20/20 [01:31&lt;00:00,  4.68s/it]"
          }
        },
        "b61d265d37164e0f9325422b9a2e700b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "095c0b732540439489d38419475a79e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6694fbff905d42a98197955fe066f061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f26b14db42a24a619b6acd8651748a96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8875cbd62d30494e82be1a42f65bf7a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5263daf6319344f18e2e5784d5007fff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b13bc16817b34610808af5884fc1afb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}